{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://lightgbm.readthedocs.io/en/v3.3.2/Python-Intro.html\n",
    "# https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "# https://coiled.io/blog/dask-dataframe-merge-join/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.dask.org/en/latest/deploying-python.html\n",
    "# https://coiled.io/blog/dask-dataframe-merge-join/  << Ctrl + F \"Run Massive Joins on Dask Cluster\"\n",
    "# Example: \n",
    "# https://github.com/microsoft/LightGBM/blob/fdc582ea6ba13faf15ee6707c7c7542790c8821d/examples/python-guide/dask/prediction.py\n",
    "# https://examples.dask.org/machine-learning.html\n",
    "# obj: create Dask cluster\n",
    "\n",
    "\n",
    "client = Client(n_workers=2, threads_per_worker=2)\n",
    "# client.restart()\n",
    "\n",
    "\n",
    "# dashboard: for task, cpu, worker load, must have bokeh installed\n",
    "# https://docs.dask.org/en/stable/dashboard.html < diagnostics\n",
    "# https://youtu.be/N_GqzcuGLCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# types of joins: https://www.geeksforgeeks.org/how-to-merge-two-csv-files-by-specific-column-using-pandas-in-python/\n",
    "# how to merge df w/ dask: https://coiled.io/blog/dask-dataframe-merge-join/\n",
    "# obj: full outer join label csv to feature csv\n",
    "\n",
    "\n",
    "\n",
    "ProgressBar().register()\n",
    "training_features = dd.read_csv(\"./originalDataset/train_data.csv\", blocksize=25e6)\n",
    "training_label = dd.read_csv(\"./originalDataset/train_labels.csv\", blocksize=25e6)\n",
    "\n",
    "training_merged = training_features.merge(\n",
    "    training_label, \n",
    "    how=\"outer\", \n",
    "    on=[\"customer_ID\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# feature engineering\n",
    "categorical_feature_array=[\n",
    "        \"B_30\", \"B_38\", \"D_114\", \n",
    "        \"D_116\", \"D_117\", \"D_120\",\n",
    "        \"D_126\", \"D_63\", \"D_64\",\n",
    "        \"D_66\", \"D_68\"\n",
    "]\n",
    "\n",
    "def feature_engineering(dataframe):\n",
    "    for c in categorical_feature_array:\n",
    "        dataframe[c] = dataframe[c].astype('category')\n",
    "\n",
    "\n",
    "training_merged = feature_engineering(training_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# features = training_merged[training_merged.columns[training_merged.columns!=\"target\"]]\n",
    "# label = training_merged[\"target\"]\n",
    "\n",
    "# must create training set, validation set, & test set using training_merged to train, validate, & test model\n",
    "\n",
    "%%time\n",
    "\n",
    "training_set, validation_set, test_set = training_merged.random_split([0.8, 0.1, 0.1], random_state=123)\n",
    "\n",
    "train_x = training_set.drop(columns=[\"target\",\"customer_ID\"])\n",
    "train_y = training_set[\"target\"]\n",
    "\n",
    "val_x = validation_set.drop(columns=[\"target\",\"customer_ID\"])\n",
    "val_y = validation_set[\"target\"]\n",
    "\n",
    "test_x = test_set.drop(columns=[\"target\",\"customer_ID\"])\n",
    "test_y = test_set[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parallel-Learning-Guide.html#dask\n",
    "# https://www.analyticsvidhya.com/blog/2021/08/complete-guide-on-how-to-use-lightgbm-in-python/\n",
    "# model development\n",
    "\n",
    "\n",
    "\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html#for-better-accuracy\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    # change accuracy, use dart bosoting type?\n",
    "    \"num_leaves\" : [31],\n",
    "    \"max_bin\" : [63],\n",
    "    \"learning_rate\" : [0.1],\n",
    "    \"num_iterations\" : [100],\n",
    "    \"boosting_type\" : [\"goss\"],\n",
    "\n",
    "    # change overfitting\n",
    "    \"max_depth\" : [-1],\n",
    "    \"min_split_gain\" : [0],\n",
    "    \"min_child_samples\" : [20],\n",
    "    \"reg_alpha\" : [0],\n",
    "    \"reg_lambda\" : [0],\n",
    "    \"early_stopping\" : [5],\n",
    "    \"feature_pre_filter\" : [True],\n",
    "\n",
    "    # 20x weight on negative\n",
    "    \"scale_pos_weight\" : [0.05],\n",
    "\n",
    "    # gpu\n",
    "    \"device_type\" : [\"gpu\"],\n",
    "    \"gpu_use_dp\" : [True],\n",
    "    \"gpu_platform_id\" : [0],\n",
    "    \"gpu_device_id\" : [0]\n",
    "\n",
    "}\n",
    "\n",
    "dask_model = lgb.DaskLGBMClassifier(\n",
    "    # client=client,  << used for cluster\n",
    "    objective=\"binary\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    **params\n",
    ")\n",
    "\n",
    "dask_model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    eval_set=[(val_x, val_y),(train_x, train_y)],\n",
    "    eval_metric=\"logloss\",\n",
    "    categorical_feature=categorical_feature_array,\n",
    "    verbose=20\n",
    ")\n",
    "\n",
    "print(f\"Training accuracy: {dask_model.score(train_x, train_y)}\")\n",
    "print(f\"Validation accuracy: {dask_model.score(val_x, val_y)}\")\n",
    "print(f\"Test accuracy: {dask_model.score(test_x, test_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# https://www.analyticsvidhya.com/blog/2021/08/complete-guide-on-how-to-use-lightgbm-in-python/\n",
    "# Additional\n",
    "from sklearn.metrics import classification_report\n",
    "lgb.plot_importance(dask_model)\n",
    "lgb.plot_metric(dask_model)\n",
    "print(classification_report(test_y,dask_model.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# make predictions on test_data features and reference sample_submission for format\n",
    "test_features_with_ID = dd.read_csv(\"./originalDataset/test_data.csv\", blocksize=25e6)\n",
    "\n",
    "# changes features to match what was used to train model\n",
    "test_features_with_ID = feature_engineering(test_features_with_ID)\n",
    "\n",
    "test_features = test_features_with_ID.drop(columns=[\"customer_ID\"])\n",
    "pred_y = dask_model.predict(test_features)\n",
    "final_submit_df = test_features_with_ID[\"customer_ID\"]\n",
    "final_submit_df[\"prediction\"] = pred_y\n",
    "final_submit_df.to_csv(\"final_submit.csv\", single_file=True)\n",
    "\n",
    "# in cli\n",
    "# kaggle competitions submit -c [COMPETITION] -f [FILE] -m [MESSAGE]\n",
    "!kaggle competitions submit -c amex-default-prediction -f final_submit.csv -m \"first submit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle model when done?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c7f0a6833b2e90d418006e0e6deec1fc5fac15b23c1dee2df1a27ddd2f0576d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
