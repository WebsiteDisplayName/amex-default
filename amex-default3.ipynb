{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "fatal: destination path 'LightGBM' already exists and is not an empty directory.\n",
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "mkdir: cannot create directory ‘build’: File exists\n",
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "\u001b[33mCMake Warning:\n",
      "  No source or binary directory provided.  Both will be assumed to be the\n",
      "  same as the current working directory, but note that this warning will\n",
      "  become a fatal error in future CMake releases.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[0mCMake Error: The source directory \"/home/ubuntu\" does not appear to contain CMakeLists.txt.\n",
      "Specify --help for usage, or press the help button on the CMake GUI.\u001b[0m\n",
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "make: *** No targets specified and no makefile found.  Stop.\n",
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n"
     ]
    }
   ],
   "source": [
    "# gpu support\n",
    "# may need to install nvidia drivers etc ref: https://lightgbm.readthedocs.io/en/latest/GPU-Tutorial.html\n",
    "!git clone --recursive https://github.com/microsoft/LightGBM\n",
    "!cd LightGBM\n",
    "!mkdir build\n",
    "!cd build\n",
    "!cmake -DUSE_GPU=1\n",
    "!make -j$(nproc)\n",
    "!cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: lightgbm in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: scipy in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from lightgbm) (1.7.2)\n",
      "Requirement already satisfied: wheel in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from lightgbm) (0.37.0)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from lightgbm) (1.0.1)\n",
      "Requirement already satisfied: numpy in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from lightgbm) (1.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/tensorflow2_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: dask[complete] in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (2021.11.1)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (21.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (2021.7.0)\n",
      "Requirement already satisfied: pyyaml in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (6.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (0.11.2)\n",
      "Requirement already satisfied: distributed==2021.11.1 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (2021.11.1)\n",
      "Requirement already satisfied: pandas>=1.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.18 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (1.20.3)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (3.0.3)\n",
      "Requirement already satisfied: bokeh!=2.0.0,>=1.0.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (2.4.2)\n",
      "Requirement already satisfied: psutil>=5.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (5.8.0)\n",
      "Requirement already satisfied: click>=6.6 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (8.0.3)\n",
      "Requirement already satisfied: tornado>=6.0.3 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (6.1)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (1.0.2)\n",
      "Requirement already satisfied: tblib>=1.6.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (1.7.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (2.0.0)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (2.4.0)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (59.1.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from bokeh!=2.0.0,>=1.0.0->dask[complete]) (9.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from bokeh!=2.0.0,>=1.0.0->dask[complete]) (3.10.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from jinja2->dask[complete]) (2.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from packaging>=20.0->dask[complete]) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from pandas>=1.0->dask[complete]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from pandas>=1.0->dask[complete]) (2021.3)\n",
      "Requirement already satisfied: locket in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from partd>=0.3.10->dask[complete]) (0.2.0)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=1.0->dask[complete]) (1.16.0)\n",
      "Requirement already satisfied: heapdict in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from zict>=0.1.3->distributed==2021.11.1->dask[complete]) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/tensorflow2_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sklearn in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.20.3)\n",
      "Requirement already satisfied: joblib>=0.11 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/tensorflow2_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "!pip install dask[complete]\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/distributed/node.py:160: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 42311 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "# client.restart()\n",
    "# client.close()\n",
    "# client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 361 ms, sys: 13.6 ms, total: 375 ms\n",
      "Wall time: 375 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# dask\n",
    "# https://youtu.be/lPcX2xev0ho\n",
    "\n",
    "training_features = dd.read_csv(\"./originalDataset/train_data.csv\", blocksize=25e6)\n",
    "training_label = dd.read_csv(\"./originalDataset/train_labels.csv\", blocksize=25e6)\n",
    "\n",
    "training_merged = training_features.merge(\n",
    "    training_label, \n",
    "    how=\"outer\", \n",
    "    on=[\"customer_ID\"]\n",
    ")\n",
    "\n",
    "# training_merged.compute()\n",
    "# training_merged.head(n=5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 888 ms, sys: 93 ms, total: 981 ms\n",
      "Wall time: 875 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# https://towardsdatascience.com/parallelizing-feature-engineering-with-dask-3db88aec33b7\n",
    "# feature engineering\n",
    "categorical_feature_array=[\n",
    "        \"B_30\", \"B_38\", \"D_114\", \n",
    "        \"D_116\", \"D_117\", \"D_120\",\n",
    "        \"D_126\", \"D_64\",\n",
    "        \"D_66\", \"D_68\"\n",
    "]\n",
    "# removed column D_63 because had ML algo (fit) couldn't understand the column & couldn't properly change type \n",
    "\n",
    "\n",
    "def feature_engineering(dataframe):\n",
    "        # dataframe[\"D_63\"] = dataframe[\"D_63\"].astype(\"category\")\n",
    "        # dataframe[\"D_64\"] = dataframe[\"D_64\"].astype(\"category\")\n",
    "\n",
    "        dataframe[categorical_feature_array] = dataframe[categorical_feature_array].astype(\"category\")\n",
    "\n",
    "        \n",
    "        dataframe[\"S_2\"] = dd.to_datetime(dataframe[\"S_2\"])\n",
    "        dataframe[\"month\"] = dataframe[\"S_2\"].dt.month\n",
    "        dataframe[\"day\"] = dataframe[\"S_2\"].dt.dayofweek\n",
    "        dataframe[\"year\"] = dataframe[\"S_2\"].dt.year\n",
    "        return dataframe.drop(columns=[\"S_2\", \"D_63\"])\n",
    "\n",
    "training_merged = feature_engineering(training_merged)\n",
    "\n",
    "# learn dask\n",
    "# https://youtu.be/lPcX2xev0ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(training_merged[[\"D_63\",\"D_64\"]].dtypes)\n",
    "# print(training_merged[\"D_64\"].head(n=5))\n",
    "# training_merged[\"D_63\"].nunique().compute()\n",
    "# training_merged[\"D_64\"].nunique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 178 ms, sys: 10.9 ms, total: 189 ms\n",
      "Wall time: 167 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# features = training_merged[training_merged.columns[training_merged.columns!=\"target\"]]\n",
    "# label = training_merged[\"target\"]\n",
    "\n",
    "# must create training set, validation set, & test set using training_merged to train, validate, & test model\n",
    "\n",
    "\n",
    "\n",
    "training_set, validation_set, test_set = training_merged.random_split([0.8, 0.1, 0.1], random_state=123)\n",
    "\n",
    "train_x = training_set.drop(columns=[\"target\",\"customer_ID\"])\n",
    "train_y = training_set[\"target\"]\n",
    "\n",
    "val_x = validation_set.drop(columns=[\"target\",\"customer_ID\"])\n",
    "val_y = validation_set[\"target\"]\n",
    "\n",
    "test_x = test_set.drop(columns=[\"target\",\"customer_ID\"])\n",
    "test_y = test_set[\"target\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62 µs, sys: 10 µs, total: 72 µs\n",
      "Wall time: 79.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parallel-Learning-Guide.html#dask\n",
    "# https://www.analyticsvidhya.com/blog/2021/08/complete-guide-on-how-to-use-lightgbm-in-python/\n",
    "# model development\n",
    "\n",
    "\n",
    "\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html#for-better-accuracy\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    # change accuracy, use dart bosoting type?\n",
    "    \"num_leaves\" : 31,\n",
    "    \"max_bin\" : 63,\n",
    "    \"learning_rate\" : 0.1,\n",
    "    \"boosting_type\" : \"goss\",\n",
    "\n",
    "    # change overfitting\n",
    "    \"max_depth\" : -1,\n",
    "    \"min_split_gain\" : 0,\n",
    "    \"min_child_samples\" : 20,\n",
    "    \"reg_alpha\" : 0,\n",
    "    \"reg_lambda\" : 0,\n",
    "    \"early_stopping\" : 5,\n",
    "    \"feature_pre_filter\" : True,\n",
    "\n",
    "    # 20x weight on negative\n",
    "    \"scale_pos_weight\" : 0.05,\n",
    "\n",
    "    # gpu\n",
    "    \"device_type\" : \"gpu\",\n",
    "    \"gpu_platform_id\" : 0,\n",
    "    \"gpu_device_id\" : 0,\n",
    "\n",
    "    # misc\n",
    "    \"verbose\" : -1,\n",
    "    \"objective\" : \"binary\",\n",
    "    \"n_jobs\" : -1,\n",
    "    \"random_state\" : 42\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model = lgb.DaskLGBMClassifier(client=client, **params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/lightgbm/dask.py:525: UserWarning: Parameter n_jobs will be ignored.\n",
      "  _log_warning(f\"Parameter {param_alias} will be ignored.\")\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/dask/highlevelgraph.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/dask/blockwise.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('split-shuffle-1-3583258fbca82f30027630c03f94fc0b', 5, (16, 25))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/lightgbm/dask.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'early_stopping_rounds is not currently supported in lightgbm.dask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m         return self._lgb_dask_fit(\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0mmodel_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/lightgbm/dask.py\u001b[0m in \u001b[0;36m_lgb_dask_fit\u001b[0;34m(self, model_factory, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, eval_at, early_stopping_rounds, **kwargs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"client\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m         model = _train(\n\u001b[0m\u001b[1;32m   1047\u001b[0m             \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_get_dask_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/lightgbm/dask.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(client, data, label, params, model_factory, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, eval_at, **kwargs)\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;31m# Start computation in the background\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m     \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m     \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, collections, sync, optimize_graph, workers, allow_other_workers, resources, retries, priority, fifo_timeout, actors, traverse, **kwargs)\u001b[0m\n\u001b[1;32m   2881\u001b[0m         \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dask_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2883\u001b[0;31m         \u001b[0mdsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollections_to_dsk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2884\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"finalize-%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2885\u001b[0m         \u001b[0mdsk2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mcollections_to_dsk\u001b[0;34m(collections, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3967\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollections_to_dsk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3968\u001b[0m         \u001b[0;34m\"\"\"Convert many collections into a single dask graph, after optimization\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3969\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcollections_to_dsk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3971\u001b[0m     def get_task_stream(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcollections_to_dsk\u001b[0;34m(collections, optimize_graph, optimizations, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_graph_and_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m             \u001b[0mdsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mopt_inner\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/dask/delayed.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(dsk, keys, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHighLevelGraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0mdsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHighLevelGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_collections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdependencies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0mdsk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdsk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdsk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/dask/highlevelgraph.py\u001b[0m in \u001b[0;36mcull\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0moutput_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m                 \u001b[0mculled_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mculled_deps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_ext_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m                 \u001b[0;31m# Update `keys` with all layer's external key dependencies, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m                 \u001b[0;31m# are all the layer's dependencies (`culled_deps`) excluding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/dask/highlevelgraph.py\u001b[0m in \u001b[0;36mcull\u001b[0;34m(self, keys, all_hlg_keys)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mwork\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0mret_deps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_hlg_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret_deps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/dask/highlevelgraph.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/dask/highlevelgraph.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    eval_set=[(val_x, val_y),(train_x, train_y)],\n",
    "    eval_metric=\"logloss\"\n",
    "    # ,categorical_feature=categorical_feature_array\n",
    ")\n",
    "\n",
    "print(f\"Training accuracy: {model.score(train_x, train_y)}\")\n",
    "print(f\"Validation accuracy: {model.score(val_x, val_y)}\")\n",
    "print(f\"Test accuracy: {model.score(test_x, test_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (request to http://localhost:8888/api/kernels?1660683386482 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# https://www.analyticsvidhya.com/blog/2021/08/complete-guide-on-how-to-use-lightgbm-in-python/\n",
    "# Additional\n",
    "from sklearn.metrics import classification_report\n",
    "lgb.plot_importance(model)\n",
    "lgb.plot_metric(model)\n",
    "print(classification_report(test_y,model.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# make predictions on test_data features and reference sample_submission for format\n",
    "test_features_with_ID = dd.read_csv(\"./originalDataset/test_data.csv\", blocksize=25e6)\n",
    "\n",
    "# changes features to match what was used to train model\n",
    "test_features_with_ID = feature_engineering(test_features_with_ID)\n",
    "\n",
    "test_features = test_features_with_ID.drop(columns=[\"customer_ID\"])\n",
    "test_features.compute()\n",
    "pred_y = model.predict(test_features)\n",
    "final_submit_df = test_features_with_ID[\"customer_ID\"]\n",
    "final_submit_df[\"prediction\"] = pred_y\n",
    "final_submit_df.to_csv(\"final_submit.csv\", single_file=True)\n",
    "\n",
    "# in cli\n",
    "# kaggle competitions submit -c [COMPETITION] -f [FILE] -m [MESSAGE]\n",
    "!kaggle competitions submit -c amex-default-prediction -f final_submit.csv -m \"first submit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle model when done?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p38)",
   "language": "python",
   "name": "conda_tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c7f0a6833b2e90d418006e0e6deec1fc5fac15b23c1dee2df1a27ddd2f0576d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
