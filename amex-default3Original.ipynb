{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "fatal: destination path 'LightGBM' already exists and is not an empty directory.\n",
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "mkdir: cannot create directory ‘build’: File exists\n",
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "\u001b[33mCMake Warning:\n",
      "  No source or binary directory provided.  Both will be assumed to be the\n",
      "  same as the current working directory, but note that this warning will\n",
      "  become a fatal error in future CMake releases.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[0mCMake Error: The source directory \"/home/ubuntu\" does not appear to contain CMakeLists.txt.\n",
      "Specify --help for usage, or press the help button on the CMake GUI.\u001b[0m\n",
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "make: *** No targets specified and no makefile found.  Stop.\n",
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n"
     ]
    }
   ],
   "source": [
    "# gpu support\n",
    "# may need to install nvidia drivers etc ref: https://lightgbm.readthedocs.io/en/latest/GPU-Tutorial.html\n",
    "!git clone --recursive https://github.com/microsoft/LightGBM\n",
    "!cd LightGBM\n",
    "!mkdir build\n",
    "!cd build\n",
    "!cmake -DUSE_GPU=1\n",
    "!make -j$(nproc)\n",
    "!cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: lightgbm in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (3.3.2)\n",
      "Requirement already satisfied: scipy in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from lightgbm) (1.7.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from lightgbm) (1.0.1)\n",
      "Requirement already satisfied: wheel in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from lightgbm) (0.37.0)\n",
      "Requirement already satisfied: numpy in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from lightgbm) (1.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/tensorflow2_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: dask[complete] in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (2021.11.1)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (21.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (0.11.2)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (2021.7.0)\n",
      "Requirement already satisfied: partd>=0.3.10 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (1.2.0)\n",
      "Requirement already satisfied: pyyaml in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (5.4.1)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (3.0.3)\n",
      "Requirement already satisfied: pandas>=1.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (1.3.4)\n",
      "Requirement already satisfied: distributed==2021.11.1 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (2021.11.1)\n",
      "Requirement already satisfied: bokeh!=2.0.0,>=1.0.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (2.4.2)\n",
      "Requirement already satisfied: numpy>=1.18 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from dask[complete]) (1.20.3)\n",
      "Requirement already satisfied: psutil>=5.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (5.8.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (2.0.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (6.1)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (59.1.1)\n",
      "Requirement already satisfied: click>=6.6 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (8.0.3)\n",
      "Requirement already satisfied: tblib>=1.6.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (1.7.0)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (2.4.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from distributed==2021.11.1->dask[complete]) (1.0.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from bokeh!=2.0.0,>=1.0.0->dask[complete]) (9.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from bokeh!=2.0.0,>=1.0.0->dask[complete]) (3.10.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from jinja2->dask[complete]) (2.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from packaging>=20.0->dask[complete]) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from pandas>=1.0->dask[complete]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from pandas>=1.0->dask[complete]) (2021.3)\n",
      "Requirement already satisfied: locket in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from partd>=0.3.10->dask[complete]) (0.2.0)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=1.0->dask[complete]) (1.16.0)\n",
      "Requirement already satisfied: heapdict in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from zict>=0.1.3->distributed==2021.11.1->dask[complete]) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/tensorflow2_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m/bin/bash: module: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `module'\n",
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sklearn in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ubuntu/anaconda3/envs/tensorflow2_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "!pip install dask[complete]\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 172 ms, sys: 6.87 ms, total: 179 ms\n",
      "Wall time: 272 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# dask\n",
    "# https://youtu.be/lPcX2xev0ho\n",
    "\n",
    "training_features = dd.read_csv(\"./originalDataset/train_data.csv\", blocksize=25e6)\n",
    "training_label = dd.read_csv(\"./originalDataset/train_labels.csv\", blocksize=25e6)\n",
    "\n",
    "training_merged = training_features.merge(\n",
    "    training_label, \n",
    "    how=\"outer\", \n",
    "    on=[\"customer_ID\"]\n",
    ")\n",
    "\n",
    "# training_merged.compute()\n",
    "# training_merged.head(n=5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# https://towardsdatascience.com/parallelizing-feature-engineering-with-dask-3db88aec33b7\n",
    "# feature engineering\n",
    "categorical_feature_array=[\n",
    "        \"B_30\", \"B_38\", \"D_114\", \n",
    "        \"D_116\", \"D_117\", \"D_120\",\n",
    "        \"D_126\", \"D_63\", \"D_64\",\n",
    "        \"D_66\", \"D_68\"\n",
    "]\n",
    "\n",
    "# def feature_engineering(dataframe):\n",
    "#         for c in categorical_feature_array:\n",
    "#                 dataframe[c] = dataframe[c].astype('category')\n",
    "#         return dataframe\n",
    "\n",
    "# training_merged = feature_engineering(training_merged)\n",
    "\n",
    "\n",
    "# learn dask\n",
    "# https://youtu.be/lPcX2xev0ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/dask/threaded.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiprocessingPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     results = get_async(\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"waiting\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ready\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"running\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mfire_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                         \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/site-packages/dask/local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p38/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# features = training_merged[training_merged.columns[training_merged.columns!=\"target\"]]\n",
    "# label = training_merged[\"target\"]\n",
    "\n",
    "# must create training set, validation set, & test set using training_merged to train, validate, & test model\n",
    "\n",
    "\n",
    "\n",
    "training_set, validation_set, test_set = training_merged.random_split([0.8, 0.1, 0.1], random_state=123)\n",
    "\n",
    "train_x = training_set.drop(columns=[\"target\",\"customer_ID\"]).compute()\n",
    "train_y = training_set[\"target\"].compute()\n",
    "\n",
    "val_x = validation_set.drop(columns=[\"target\",\"customer_ID\"]).compute()\n",
    "val_y = validation_set[\"target\"].compute()\n",
    "\n",
    "test_x = test_set.drop(columns=[\"target\",\"customer_ID\"]).compute()\n",
    "test_y = test_set[\"target\"].compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53 µs, sys: 0 ns, total: 53 µs\n",
      "Wall time: 58.7 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parallel-Learning-Guide.html#dask\n",
    "# https://www.analyticsvidhya.com/blog/2021/08/complete-guide-on-how-to-use-lightgbm-in-python/\n",
    "# model development\n",
    "\n",
    "\n",
    "\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html#for-better-accuracy\n",
    "\n",
    "\n",
    "\n",
    "params = {\n",
    "    # change accuracy, use dart bosoting type?\n",
    "    \"num_leaves\" : 31,\n",
    "    \"max_bin\" : 63,\n",
    "    \"learning_rate\" : 0.1,\n",
    "    \"boosting_type\" : \"goss\",\n",
    "\n",
    "    # change overfitting\n",
    "    \"max_depth\" : -1,\n",
    "    \"min_split_gain\" : 0,\n",
    "    \"min_child_samples\" : 20,\n",
    "    \"reg_alpha\" : 0,\n",
    "    \"reg_lambda\" : 0,\n",
    "    \"early_stopping\" : 5,\n",
    "    \"feature_pre_filter\" : True,\n",
    "\n",
    "    # 20x weight on negative\n",
    "    \"scale_pos_weight\" : 0.05,\n",
    "\n",
    "    # gpu\n",
    "    \"device_type\" : \"gpu\",\n",
    "    \"gpu_platform_id\" : 0,\n",
    "    \"gpu_device_id\" : 0,\n",
    "\n",
    "    # misc\n",
    "    \"verbose\" : -1,\n",
    "    \"objective\" : \"binary\",\n",
    "    \"n_jobs\" : -1,\n",
    "    \"random_state\" : 42\n",
    "}\n",
    "\n",
    "model = lgb.LGBMClassifier(**params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    eval_set=[(val_x, val_y),(train_x, train_y)],\n",
    "    eval_metric=\"logloss\",\n",
    "    categorical_feature=categorical_feature_array\n",
    ")\n",
    "\n",
    "print(f\"Training accuracy: {model.score(train_x, train_y)}\")\n",
    "print(f\"Validation accuracy: {model.score(val_x, val_y)}\")\n",
    "print(f\"Test accuracy: {model.score(test_x, test_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# https://www.analyticsvidhya.com/blog/2021/08/complete-guide-on-how-to-use-lightgbm-in-python/\n",
    "# Additional\n",
    "from sklearn.metrics import classification_report\n",
    "lgb.plot_importance(model)\n",
    "lgb.plot_metric(model)\n",
    "print(classification_report(test_y,model.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# make predictions on test_data features and reference sample_submission for format\n",
    "test_features_with_ID = dd.read_csv(\"./originalDataset/test_data.csv\", blocksize=25e6)\n",
    "\n",
    "# changes features to match what was used to train model\n",
    "# test_features_with_ID = feature_engineering(test_features_with_ID)\n",
    "\n",
    "test_features = test_features_with_ID.drop(columns=[\"customer_ID\"])\n",
    "test_features.compute()\n",
    "pred_y = model.predict(test_features)\n",
    "final_submit_df = test_features_with_ID[\"customer_ID\"]\n",
    "final_submit_df[\"prediction\"] = pred_y\n",
    "final_submit_df.to_csv(\"final_submit.csv\", single_file=True)\n",
    "\n",
    "# in cli\n",
    "# kaggle competitions submit -c [COMPETITION] -f [FILE] -m [MESSAGE]\n",
    "!kaggle competitions submit -c amex-default-prediction -f final_submit.csv -m \"first submit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle model when done?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c7f0a6833b2e90d418006e0e6deec1fc5fac15b23c1dee2df1a27ddd2f0576d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
